{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from typing import List\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import nltk\n",
    "import gensim\n",
    "import gensim.downloader as gensim_api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Evaluation for ROUGE score and Semantic Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. Process output of GeneAgent and GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = []\n",
    "genes = []\n",
    "# data = pd.read_table(\"NeST_table.tsv\", header=0, index_col=0)\n",
    "data = pd.read_csv(\"Datasets/MsigDB/MsigDB.csv\",header=0, index_col=None)\n",
    "for gene, term in zip(data[\"Genes\"], data[\"Name\"]):\n",
    "    term = term.replace('/', ' ').replace(\",\",\" \").replace(\"\\\"\",\"\").replace(\"-\", \" \").strip()\n",
    "    genes.append(gene)\n",
    "    reference.append(term)\n",
    "    \n",
    "print(len(genes))\n",
    "print(len(reference))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text: str) -> list:\n",
    "    pattern = r'\\([^)]*\\)'\n",
    "    segments = text.split('//')\n",
    "    # Remove numbers and stop tokens ('-', '*')\n",
    "    cleaned_segments = []\n",
    "    for segment in segments:\n",
    "        cleaned_segment = ''.join(char for char in segment)\n",
    "        cleaned_segment = re.sub(pattern, '', cleaned_segment)\n",
    "        cleaned_segment = cleaned_segment.replace('/', ' ').replace(\",\",\" \").replace(\"\\\"\",\"\").replace(\"-\", \" \").strip()\n",
    "        if cleaned_segment:\n",
    "            cleaned_segments.append(cleaned_segment)\n",
    "\n",
    "    return cleaned_segments\n",
    "\n",
    "## read results of GeneAgent\n",
    "agent = \"\"\n",
    "with open (\"Outputs/GeneAgent/Cascade/MsigDB_Final_Response_GeneAgent.txt\", \"r\") as agentfile:\n",
    "    for line in agentfile.readlines():\n",
    "        agent += line\n",
    "agent_text = process_text(agent)\n",
    "agent_term = []\n",
    "for text in agent_text:\n",
    "    seg = text.split(\"\\n\")\n",
    "    if len(seg) > 1:\n",
    "        agent_term.append(seg[0].split(\": \")[1])\n",
    "    else:\n",
    "        agent_term.append(\"None\")\n",
    "print(\"gpt agent file: %d\" %(len(agent_term)))\n",
    "        \n",
    "## read results of GPT4\n",
    "gpt = \"\"\n",
    "with open (\"Outputs/GPT-4/MsigDB_Response_GPT4.txt\", \"r\") as gptfile:\n",
    "    for line in gptfile.readlines():\n",
    "        gpt += line\n",
    "gpt_text = process_text(gpt)\n",
    "gpt_term = []\n",
    "for text in gpt_text:\n",
    "    seg = text.split(\"\\n\")\n",
    "    if len(seg) > 1:\n",
    "        gpt_term.append(seg[0].split(\": \")[1])\n",
    "    else:\n",
    "        gpt_term.append(\"None\")\n",
    "print(\"gpt file:%d\" %(len(gpt_term)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. Calculate ROUGE scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from rouge_score import rouge_scorer\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\tmetrics = [\"rouge1\", \"rouge2\", \"rougeL\"]\n",
    "\tmetric2results = {metric: [] for metric in metrics}\n",
    "\tscorer = rouge_scorer.RougeScorer(metrics, use_stemmer=True)\n",
    " \n",
    "\tfor ref, hypagent in zip (reference, agent_term):\n",
    "    # for ref, hypgpt in zip (reference, gpt_term):\n",
    "\t\tscores_agent = scorer.score(ref, hypagent)\n",
    "\t\t# scores_gpt = scorer.score(ref, hypgpt)\n",
    "\n",
    "\t\tfor metric in metrics:\n",
    "\t\t\tmetric2results[metric].append(scores_gpt[metric].fmeasure)\n",
    "   \n",
    "\tf = open(\"MsigDB.Rouge.txt\",\"a\")\n",
    "\tf.write(\"\\n====GeneAgent (Cascade)====\\n\")\n",
    "\tfor metric in metrics:\n",
    "\t\tresults = metric2results[metric]\n",
    "\t\tf.write(metric + \":\" + str(sum(results) / len(results)) + \"\\n\")\n",
    "\tf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-3. Calculate semantic similarity using MedCPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "model = AutoModel.from_pretrained(\"ncbi/MedCPT-Query-Encoder\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ncbi/MedCPT-Query-Encoder\")\n",
    "\n",
    "def cos_sim(a: Tensor, b: Tensor):\n",
    "    \"\"\"\n",
    "    Computes the cosine similarity cos_sim(a[i], b[j]) for all i and j.\n",
    "    :return: Matrix with res[i][j]  = cos_sim(a[i], b[j])\n",
    "    \"\"\"\n",
    "    if not isinstance(a, torch.Tensor):\n",
    "        a = torch.tensor(a)\n",
    "\n",
    "    if not isinstance(b, torch.Tensor):\n",
    "        b = torch.tensor(b)\n",
    "\n",
    "    if len(a.shape) == 1:\n",
    "        a = a.unsqueeze(0)\n",
    "\n",
    "    if len(b.shape) == 1:\n",
    "        b = b.unsqueeze(0)\n",
    "\n",
    "    a_norm = torch.nn.functional.normalize(a, p=2, dim=1)\n",
    "    b_norm = torch.nn.functional.normalize(b, p=2, dim=1)\n",
    "    return torch.mm(a_norm, b_norm.transpose(0, 1))\n",
    "\n",
    "agent_scores = []\n",
    "gpt_scores = []\n",
    "summary_scores = []\n",
    "\n",
    "for ref, hypagent, hypgpt in zip(reference, agent_term, gpt_term):\n",
    "    with torch.no_grad():\n",
    "        tokenize the queries\n",
    "        encoded_agent = tokenizer(\n",
    "            [ref, hypagent], \n",
    "            truncation=True, \n",
    "            padding=True, \n",
    "            return_tensors='pt', \n",
    "            max_length=64,\n",
    "        )\n",
    "        encoded_gpt = tokenizer(\n",
    "            [ref, hypgpt], \n",
    "            truncation=True, \n",
    "            padding=True, \n",
    "            return_tensors='pt', \n",
    "            max_length=64,\n",
    "        )\n",
    "        \n",
    "        # encode the queries (use the [CLS] last hidden states as the representations)\n",
    "        embeds_agent = model(**encoded_agent).last_hidden_state[:, 0, :] \n",
    "        score_agent = cos_sim(embeds_agent[0], embeds_agent[1])\n",
    "        agent_scores.append(score_agent.tolist()[0])\n",
    "        \n",
    "        embeds_gpt = model(**encoded_gpt).last_hidden_state[:, 0, :]\n",
    "        score_gpt = cos_sim(embeds_gpt[0], embeds_gpt[1])\n",
    "        gpt_scores.append(score_gpt.tolist()[0])\n",
    "        \n",
    "        \n",
    "print(np.average(agent_scores),np.average(gpt_scores))\n",
    "print(np.max(agent_scores),np.max(gpt_scores))  \n",
    "      \n",
    "np.savetxt(\"MsigDB.GeneAgent.Cascade.Semantic.csv\", np.asarray(agent_scores), fmt=\"%s\", delimiter=\"\\t\", newline=\"\\n\") \n",
    "np.savetxt(\"MsigDB.GPT4.Semantic.csv\", np.asarray(gpt_scores), fmt=\"%s\", delimiter=\"\\t\", newline=\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Evaluation for background semantic similarity distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. Collect the background gene sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GSS = []\n",
    "\n",
    "index = 0\n",
    "bp = pd.read_csv(\"BP_terms_All.csv\", header=0, index_col=0)\n",
    "for ID, Genes, Count, Name in zip(bp[\"ID\"], bp[\"Genes\"], bp[\"Gene_Count\"], bp[\"Truth Label\"]):\n",
    "    GSS.append([index, ID, Genes, Count, Name])\n",
    "    index += 1\n",
    "        \n",
    "print(len(GSS))\n",
    "\n",
    "with open(\"Datasets/NeST/NeST_table.tsv\", \"r\") as nestfile:\n",
    "    for line in nestfile.readlines()[1:]:\n",
    "        arr = line.split(\"\\t\")\n",
    "        ID = arr[0]\n",
    "        Name = arr[1]\n",
    "        Genes = \" \".join(arr[2].split(\",\")).replace(\"\\n\",\"\").replace(\"\\\"\", \"\")\n",
    "        Count = len(Genes.split())\n",
    "        GSS.append([index, ID, Genes, Count, Name])\n",
    "        index += 1\n",
    "        \n",
    "print(len(GSS))\n",
    "\n",
    "\n",
    "zen = pd.read_csv(\"Datasets/MsigDB/MsigDB.csv\", header=0, index_col=None)\n",
    "for ID, Genes, Count, Name in zip(zen[\"ID\"], zen[\"Genes\"], zen[\"Count\"], zen[\"Name\"]):\n",
    "    GSS.append([index, ID, Genes, Count, Name])\n",
    "    index += 1\n",
    "        \n",
    "print(len(GSS))\n",
    "print(index)\n",
    "\n",
    "\n",
    "with open(\"background.csv\", mode='w', newline='\\n', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file, quoting=csv.QUOTE_ALL)  \n",
    "    writer.writerow(['Index', 'ID', 'Genes', 'Count', 'Term'])\n",
    "    for term in GSS:\n",
    "        writer.writerow(term)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. Calculate relative similarity using MedCPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "back = pd.read_csv(\"background.csv\", header=0, index_col=0)\n",
    "back[\"Index\"] = back.index\n",
    "\n",
    "all_Ref = []\n",
    "for term in back[\"Term\"]:\n",
    "    all_Ref.append(term)\n",
    "print(len(all_Ref))\n",
    "\n",
    "data = pd.read_csv(\"Datasets/MsigDB/MsigDB.csv\", header=0, index_col=None)\n",
    "AllDATA = pd.merge(data, back, on='ID', how='inner')\n",
    "AllDATA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "model = AutoModel.from_pretrained(\"ncbi/MedCPT-Query-Encoder\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ncbi/MedCPT-Query-Encoder\")\n",
    "\n",
    "def get_medcpt_embeddings(queries):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        encoded = tokenizer(\n",
    "            queries, \n",
    "            truncation=True, \n",
    "            padding=True, \n",
    "            return_tensors='pt', \n",
    "            max_length=64,\n",
    "        )\n",
    "        \n",
    "        embeds = model(**encoded).last_hidden_state[:, 0, :]      \n",
    "        return embeds, embeds.size()  \n",
    "\n",
    "ref_embeds, ref_embeds_size = get_medcpt_embeddings(all_Ref)\n",
    "agent_embeds, agent_embeds_size = get_medcpt_embeddings(agent_term)\n",
    "gpt_embeds, gpt_embeds_size = get_medcpt_embeddings(gpt_term) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos = torch.nn.CosineSimilarity(dim=0, eps=1e-6)\n",
    "\n",
    "relative = []\n",
    "for gpt_tensor in tqdm(gpt_embeds):\n",
    "    temp = []\n",
    "    for ref_tensor in ref_embeds:\n",
    "        score = cos(gpt_tensor, ref_tensor)\n",
    "        temp.append(score.tolist())\n",
    "\n",
    "    relative.append(temp)\n",
    "\n",
    "scores = np.asarray(relative)\n",
    "print (scores.shape)\n",
    "        \n",
    "rank = []\n",
    "row = 0\n",
    "for ind in tqdm(AllDATA[\"Index\"]):\n",
    "    root = scores[row][ind]\n",
    "    ith = 1\n",
    "    for j in range(scores.shape[1]):\n",
    "        if scores[row][j] > root:\n",
    "            ith += 1 \n",
    "    rank.append(ith)\n",
    "    row += 1\n",
    "    \n",
    "np.savetxt(\"MsigDB.Relative.Rank.GPT.Background.txt\", np.asarray(rank), fmt=\"%s\", newline=\"\\n\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Evaluation for multiple enrichment terms test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1. Process output of GPT-4 in summarizing multiple enrichment terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\n",
    "with open(\"Outputs/EnrichedTermTest/gpt.geneagent.msigdb.summary.result.verification.txt\") as summary:\n",
    "    for line in summary.readlines():\n",
    "        text += line\n",
    "segments = text.split('//')\n",
    "print(len(segments))\n",
    "enrich_terms = []\n",
    "for segment in segments:\n",
    "    cleaned_segment = ''.join(char for char in segment)\n",
    "    enrich = cleaned_segment.split(\"\\n\\n\")[-2].replace(\".\", \"\").replace(\"\\n\",\"\")\n",
    "    enrich_terms.append(enrich.split(\"Enriched Terms: \")[1].split(\"; \"))\n",
    "    \n",
    "print(len(enrich_terms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2. Exact match with all significant enrichment terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"GSEATerms/MsigDB.EnrichTerms.Allsignificant.json\",\"r\") as file:\n",
    "    enrich = json.load(file)\n",
    "    \n",
    "name2id = {}\n",
    "for names in enrich:\n",
    "    for name in names:\n",
    "        if name[\"name\"].lower() in name2id.keys():\n",
    "            name2id[name[\"name\"].lower()].append(name[\"native\"])\n",
    "        else:\n",
    "            name2id[name[\"name\"].lower()] = [name[\"native\"]]\n",
    "\n",
    "results = []\n",
    "for terms in enrich_terms:\n",
    "    matched = {} \n",
    "    for term in terms:\n",
    "        if term.lower() in name2id.keys():\n",
    "            matched[term] = list(set(name2id[term.lower()]))\n",
    "        else:\n",
    "            matched[term] = \"None\"\n",
    "\n",
    "    results.append(matched)\n",
    "        \n",
    "with open(\"Term2Enrich_Exact.Verification.Allsignificant.json\", \"w\") as file:\n",
    "    json.dump(results, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Term2Enrich_Exact.Verification.Allsignificant.json\",\"r\") as enrichfile:\n",
    "    data = json.load(enrichfile)\n",
    "print(len(data))\n",
    "\n",
    "total, success, fail = 0, 0, 0\n",
    "for terms in data:\n",
    "    for key in terms.keys():\n",
    "        total += 1\n",
    "        if terms[key] != \"None\":\n",
    "            success += 1\n",
    "        else:\n",
    "            fail += 1\n",
    "\n",
    "print(f\"the total number of summarized terms: {total}\")\n",
    "print(f\"the successful number of summarized terms: {success}\")\n",
    "print(f\"the failed number of summarized terms: {fail}\")\n",
    "print(f\"the match rate of summarized terms: {float(success/total)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-3. Exact match with top-k (k=1,3,5) significant enrichment terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Exact MATCH with ENRICHED TERMS in TOP 1\n",
    "with open(\"GSEATerms/MsigDB.EnrichTerms.top1.json\",\"r\") as file:\n",
    "    enrich = json.load(file)\n",
    "\n",
    "for ind in range(0, len(enrich_terms)):\n",
    "    for pos in range(0, len(enrich_terms[ind])):\n",
    "        enrich_terms[ind][pos] = enrich_terms[ind][pos].lower().replace(\"-\",\" \")\n",
    "\n",
    "pairs = []\n",
    "for terms, data in zip(enrich_terms, enrich):\n",
    "    temp = {}\n",
    "    if data[\"name\"].lower().replace(\"-\",\" \") in terms:\n",
    "        temp[data[\"name\"]] = data[\"native\"]\n",
    "    else:\n",
    "        temp[data[\"name\"]] = \"None\"\n",
    "        \n",
    "    pairs.append(temp)\n",
    "    \n",
    "print(len(pairs))\n",
    "with open(\"Term2Enrich_Exact.Verification.top1.json\", \"w\") as file:\n",
    "    json.dump(pairs, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Exact MATCH with ENRICHED TERMS in TOP 3 and TOP 5\n",
    "with open(\"GSEATerms/MsigDB.EnrichTerms.top5.json\",\"r\") as file:\n",
    "    enrich = json.load(file)\n",
    "    \n",
    "name2id = {}\n",
    "for names in enrich:\n",
    "    for name in names:\n",
    "        if name[\"name\"].lower() in name2id.keys():\n",
    "            name2id[name[\"name\"].lower()].append(name[\"native\"])\n",
    "        else:\n",
    "            name2id[name[\"name\"].lower()] = [name[\"native\"]]\n",
    "    \n",
    "results = []\n",
    "for terms in enrich_terms:\n",
    "    matched = {} \n",
    "    for term in terms:\n",
    "        if term.lower() in name2id.keys():\n",
    "            matched[term] = list(set(name2id[term.lower()]))\n",
    "        else:\n",
    "            matched[term] = \"None\"\n",
    "\n",
    "    results.append(matched)\n",
    "        \n",
    "with open(\"Term2Enrich_Exact.Verification.Top5.json\", \"w\") as file:\n",
    "    json.dump(results, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Term2Enrich_Exact.Verification.Top5.json\",\"r\") as gofile:\n",
    "    data = json.load(gofile)\n",
    "print(len(data))\n",
    "\n",
    "total, success, fail = 0, 0, 0\n",
    "for terms in data:\n",
    "    total += 1\n",
    "    for key in terms.keys():\n",
    "        if terms[key] != \"None\":\n",
    "            success += 1\n",
    "            break\n",
    "        else:\n",
    "            # fail += 1\n",
    "            continue\n",
    "\n",
    "print(f\"the total number of summarized terms: {total}\")\n",
    "print(f\"the successful number of summarized terms: {success}\")\n",
    "print(f\"the failed number of summarized terms: {total - success}\")\n",
    "print(f\"the match rate of summarized terms: {float(success/total)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Other BERT-based model for the evaluation of semantic similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SENTENCE BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "  dev = \"cuda:3\"\n",
    "else:\n",
    "  dev = \"cpu\"\n",
    "torch.cuda.set_device(dev)\n",
    "\n",
    "from text2vec import Similarity\n",
    "sim_model = Similarity()\n",
    "scores = []\n",
    "# for ref, hyp in zip(reference, hypothesis_term):\n",
    "for ref, hyp in zip(reference, agent_term):\n",
    "  score = sim_model.get_score(ref, hyp)\n",
    "  scores.append(score)\n",
    "\n",
    "print(np.average(scores),np.max(scores))\n",
    "# np.savetxt(\"semantic_similarity_nest_enrichment.txt\", np.asarray(scores), fmt=\"%s\", delimiter=\"\\t\\t\", newline=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SapBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel  \n",
    "\n",
    "def cos_sim(a: Tensor, b: Tensor):\n",
    "    \"\"\"\n",
    "    Computes the cosine similarity cos_sim(a[i], b[j]) for all i and j.\n",
    "    :return: Matrix with res[i][j]  = cos_sim(a[i], b[j])\n",
    "    \"\"\"\n",
    "    if not isinstance(a, torch.Tensor):\n",
    "        a = torch.tensor(a)\n",
    "\n",
    "    if not isinstance(b, torch.Tensor):\n",
    "        b = torch.tensor(b)\n",
    "\n",
    "    if len(a.shape) == 1:\n",
    "        a = a.unsqueeze(0)\n",
    "\n",
    "    if len(b.shape) == 1:\n",
    "        b = b.unsqueeze(0)\n",
    "\n",
    "    a_norm = torch.nn.functional.normalize(a, p=2, dim=1)\n",
    "    b_norm = torch.nn.functional.normalize(b, p=2, dim=1)\n",
    "    return torch.mm(a_norm, b_norm.transpose(0, 1))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cambridgeltl/SapBERT-from-PubMedBERT-fulltext\")  \n",
    "model = AutoModel.from_pretrained(\"cambridgeltl/SapBERT-from-PubMedBERT-fulltext\").cuda()\n",
    "\n",
    "# replace with your own list of entity names\n",
    "# all_names = [\"covid-19\", \"Coronavirus infection\", \"high fever\", \"Tumor of posterior wall of oropharynx\"] \n",
    "\n",
    "# bs = 128 # batch size during inference\n",
    "# all_embs = []\n",
    "# for i in tqdm(np.arange(0, len(all_names), bs)):\n",
    "scores = []\n",
    "for ref, hyp in zip(reference, gpt_term):\n",
    "    toks = tokenizer.batch_encode_plus([ref, hyp], \n",
    "                                       padding=\"max_length\", \n",
    "                                       max_length=30, \n",
    "                                       truncation=True,\n",
    "                                       return_tensors=\"pt\")\n",
    "    toks_cuda = {}\n",
    "    for k,v in toks.items():\n",
    "        toks_cuda[k] = v.cuda()\n",
    "    cls_rep = model(**toks_cuda)[0][:,0,:] # use CLS representation as the embedding\n",
    "    score = cos_sim(cls_rep[0], cls_rep[1])\n",
    "    scores.append(score.tolist()[0])\n",
    "    \n",
    "print(np.average(scores),np.max(scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wzz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
